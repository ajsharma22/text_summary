{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     D:\\Users\\A1015888\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Library Loading\n",
    "\n",
    "import bs4 as bs\n",
    "import urllib.request\n",
    "import re\n",
    "import pandas as pd\n",
    "import nltk \n",
    "import string\n",
    "string.punctuation\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "class text_summary:\n",
    "    \"\"\"A library with  to get summary of the articles using multiple options\"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean punctuation, lower case, replace newline and extra white spaces\n",
    "def clean_words(text):\n",
    "    #removing stop words first\n",
    "#   text = \"\".join([x for x in text if word not in stopwords])\n",
    "    text  = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    text = re.sub('[0-9]+', '', text)\n",
    "#     \n",
    "\n",
    "    text = punctuation_rmv(text).lower().replace('\\n', ' ').replace(\" s \", \" \")\n",
    "    \n",
    "    \n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean the text\n",
    "def clean_data_text(data=data):\n",
    "    # also included removing stop words part but not in this case later we will check\n",
    "    data['tokenized_sents'] = data['tokenized_sents'].apply(clean_words)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates sentence list \n",
    "def create_sent(data=data):\n",
    "    data['sentences_list'] = data['article_text'].apply(nltk.sent_tokenize)\n",
    "    data['tokenized_sents'] = data['article_text'].astype(str)\n",
    "    data = clean_data_text(data) # cleaning the article\n",
    "    data['tokenized_sents_copy'] = data['tokenized_sents'] #creating copy of sentence without changes\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_words_frequency_dictionary(data=data):\n",
    "    from collections import Counter\n",
    "    data['frequency'] = data['tokenized_sents_copy'].str.split(' ').apply(Counter)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_maximum_frequency(freq_dic):\n",
    "    return max(freq_dic.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_word_weighted_freq(row_dictionary):\n",
    "    max_weight = get_maximum_frequency(row_dictionary)\n",
    "    for key, val in row_dictionary.items():\n",
    "        row_dictionary[key] = val/max_weight\n",
    "    return row_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "#return max key value pair\n",
    "def get_max_key_value(freq_dic):\n",
    "    max_key_value_dic = {}\n",
    "    k = max(freq_dic, key = freq_dic.get)\n",
    "    max_key_value_dic[k] = freq_dic[k]\n",
    "    return max_key_value_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_function\n",
    "def insert_max_word_key_value(data=data):\n",
    "    data['max'] = data['frequency'].apply(get_max_key_value)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the sentence score\n",
    "def calculate_sentence_score(sentence_list, \n",
    "                             word_weight_dictionary,\n",
    "                            decided_len=30):\n",
    "    sentence_score = {}\n",
    "#     print('step 1')\n",
    "    for sent in sentence_list:\n",
    "#         print(f'sent: {sent}')\n",
    "        if len(sent.split(' ')) < decided_len:\n",
    "            for word in nltk.word_tokenize(sent):\n",
    "#                 print(f'{word}')\n",
    "                if sent not in sentence_score.keys():\n",
    "                    \n",
    "                    sentence_score[sent] = word_weight_dictionary[word]\n",
    "#                     print(f'{sentence_score[sent]}')\n",
    "#                     print(f'word searched {word}')\n",
    "#                     print(f'word_weight_dictionary value First time:{sent} and value\\n {word_weight_dictionary[word]}')\n",
    "                else:\n",
    "#                     print('why this is not printing')\n",
    "                    sentence_score[sent] += word_weight_dictionary[word]\n",
    "#                     print(f'word {word_weight_dictionary[word]} {sentence_score[word]}')\n",
    "#                     print(f'word_weight_dictionary value other time time: {sent} and value\\n {word_weight_dictionary[word]}')\n",
    "    \n",
    "#     sentence_score = sorted(sentence_score, key = sentence_score.get, reverse=True)\n",
    "    return [sentence_score]\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data loading\n",
    "data = pd.read_csv('tennis_articles.csv',encoding = 'unicode_escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create sentences\n",
    "\n",
    "data = create_sent(data)\n",
    "# create word frequency dictionary\n",
    "data = create_words_frequency_dictionary(data)\n",
    "\n",
    "data = insert_max_word_key_value(data)\n",
    "\n",
    "# this function has one bug, it is changing the main column of frequency also.\n",
    "data['weighted_freq'] = data['frequency'].apply(create_word_weighted_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['sentences_scores_dict'] = 0\n",
    "data['summary'] = 0\n",
    "summary_sent_len = 7\n",
    "data['summary'] = data['summary'].astype('O')\n",
    "for i in range(data.shape[0]):\n",
    "    dictionary_of_sent_scores = calculate_sentence_score(data['sentences_list'][i],\n",
    "                                                         word_weight_dictionary=data['weighted_freq'][i]) \n",
    "\n",
    "    data.loc[i, 'sentences_scores_dict'] = dictionary_of_sent_scores\n",
    "    data.at[data.index[i], 'summary'] = sorted(data.loc[data.index[i], 'sentences_scores_dict'],\n",
    "                                 key = data.loc[data.index[i], 'sentences_scores_dict'].get)\n",
    "    data.loc[i, 'summary'] = \" \".join(list(data.loc[i, 'summary'])[:summary_sent_len])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>article_title</th>\n",
       "      <th>article_text</th>\n",
       "      <th>source</th>\n",
       "      <th>sentences_list</th>\n",
       "      <th>tokenized_sents</th>\n",
       "      <th>tokenized_sents_copy</th>\n",
       "      <th>frequency</th>\n",
       "      <th>max</th>\n",
       "      <th>weighted_freq</th>\n",
       "      <th>sentences_scores_dict</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>TCS a Leader in System Integrator Capabilities...</td>\n",
       "      <td>TCS a Leader in System Integrator Capabilities...</td>\n",
       "      <td>https://www.tcs.com/leader-system-integrator-c...</td>\n",
       "      <td>[TCS a Leader in System Integrator Capabilitie...</td>\n",
       "      <td>tcs a leader in system integrator capabilities...</td>\n",
       "      <td>tcs a leader in system integrator capabilities...</td>\n",
       "      <td>{'tcs': 0.3, 'a': 0.5, 'leader': 0.1, 'in': 0....</td>\n",
       "      <td>{'and': 30}</td>\n",
       "      <td>{'tcs': 0.3, 'a': 0.5, 'leader': 0.1, 'in': 0....</td>\n",
       "      <td>{'The report highlights TCS industry-focused ...</td>\n",
       "      <td>To date, it has successfully completed over 95...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>OptumInsight and Change Healthcare Combine to ...</td>\n",
       "      <td>Optum, a diversified health services company a...</td>\n",
       "      <td>https://www.optum.com/about-us/news/optuminsig...</td>\n",
       "      <td>[Optum, a diversified health services company ...</td>\n",
       "      <td>optum a diversified health services company an...</td>\n",
       "      <td>optum a diversified health services company an...</td>\n",
       "      <td>{'optum': 0.10204081632653061, 'a': 0.22448979...</td>\n",
       "      <td>{'and': 49}</td>\n",
       "      <td>{'optum': 0.10204081632653061, 'a': 0.22448979...</td>\n",
       "      <td>{'Optum, a diversified health services company...</td>\n",
       "      <td>Change Healthcare brings deep patient communic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                      article_title  \\\n",
       "0           1  TCS a Leader in System Integrator Capabilities...   \n",
       "1           2  OptumInsight and Change Healthcare Combine to ...   \n",
       "\n",
       "                                        article_text  \\\n",
       "0  TCS a Leader in System Integrator Capabilities...   \n",
       "1  Optum, a diversified health services company a...   \n",
       "\n",
       "                                              source  \\\n",
       "0  https://www.tcs.com/leader-system-integrator-c...   \n",
       "1  https://www.optum.com/about-us/news/optuminsig...   \n",
       "\n",
       "                                      sentences_list  \\\n",
       "0  [TCS a Leader in System Integrator Capabilitie...   \n",
       "1  [Optum, a diversified health services company ...   \n",
       "\n",
       "                                     tokenized_sents  \\\n",
       "0  tcs a leader in system integrator capabilities...   \n",
       "1  optum a diversified health services company an...   \n",
       "\n",
       "                                tokenized_sents_copy  \\\n",
       "0  tcs a leader in system integrator capabilities...   \n",
       "1  optum a diversified health services company an...   \n",
       "\n",
       "                                           frequency          max  \\\n",
       "0  {'tcs': 0.3, 'a': 0.5, 'leader': 0.1, 'in': 0....  {'and': 30}   \n",
       "1  {'optum': 0.10204081632653061, 'a': 0.22448979...  {'and': 49}   \n",
       "\n",
       "                                       weighted_freq  \\\n",
       "0  {'tcs': 0.3, 'a': 0.5, 'leader': 0.1, 'in': 0....   \n",
       "1  {'optum': 0.10204081632653061, 'a': 0.22448979...   \n",
       "\n",
       "                               sentences_scores_dict  \\\n",
       "0  {'The report highlights TCS industry-focused ...   \n",
       "1  {'Optum, a diversified health services company...   \n",
       "\n",
       "                                             summary  \n",
       "0  To date, it has successfully completed over 95...  \n",
       "1  Change Healthcare brings deep patient communic...  "
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
